---
layout: post
title: "多卡并行DDP训练问题"
subtitle: "DDP训练模型时GPU利用率0% 100%反复跳动的问题"
date: 2025-08-06
author: "Can"
header-img: "img/post-bg-halting.jpg"
tags: ["PyTorch", "DDP"]
---

## 问题描述

* GPU 在训练过程中 间歇性利用率为 0%  
    * 每个 iteration 开始时 GPU 会短暂运行几秒（峰值约 80~100%）
    * 然后利用率迅速回落为 0%，等待数秒后再次开始下一个 batch。
* 总体训练速度变慢，samples/s 明显低于硬件理论能力

## 排查思路
1. 打印每个batch的加载时间，如果数据加载耗时远大于前向/反向传播时间，那就是 数据加载成为瓶颈

    ```python
    start = time.time()
    img, label = next(data_iter)
    print("Data loading time:", time.time() - start)
    ```

2. 是否使用到了足够多的num_workers
3. 是否启用了 pin_memory=True（加速 CPU→GPU 数据拷贝）
4. 是否关闭了 persistent_workers=False，每次 epoch 都要重新初始化线程
5. 减小 batch_size 看是否加快速度（排除 GPU 显存瓶颈）

## 原因

**GPU计算速度远高于 CPU 与IO设备（如磁盘）的数据准备速度**，尤其是在图像任务中，数据加载和预处理（如 transforms）占用了主线程或子线程大量时间，导致**GPU空转等待数据输入**。当 GPU 处理完一个batch后，如果下一个batch的数据还没准备好（还在磁盘读取或CPU预处理），就会出现GPU空转、利用率为0%的现象。这种状况就叫“数据瓶颈”：磁盘读取和 CPU 处理的速度跟不上 GPU 的计算速度，GPU 就不得不等待数据，导致训练速度下降、资源浪费。

## 解决方法

*  引入 DataPrefetcher异步预取模块
    * 原理：在CPU上创建一个prefetcher线程，利用 CUDAStream 异步加载、转换、并将数据搬到 GPU。在一个 iteration 运算过程中，并行预取下一个 batch。
    * 优势：
        * 减少了数据加载和预处理的时间，提高了数据利用效率。
        * 避免了 GPU 等待数据的时间，充分利用了 GPU 计算资源。
    * 实现：
        * 利用 PyTorch 提供的 DataLoader 类，设置 num_workers 大于 0，开启多线程异步加载。
        * 在每个 batch 加载完成后，利用 CUDAStream 将数据异步拷贝到 GPU。
        * 在每个 batch 处理完成后，利用 CUDAStream 异步将下一个 batch 数据加载到 CPU。

```python
import torch

class DataPrefetcher:
    def __init__(self, loader, device):
        self.loader = iter(loader)
        self.device = device
        self.stream = torch.cuda.Stream(device=device)
        self.preload()

    def preload(self):
        try:
            self.next_inputs = next(self.loader)
        except StopIteration:
            self.next_inputs = None
            return
        with torch.cuda.stream(self.stream):
            if isinstance(self.next_inputs, (list, tuple)):
                self.next_inputs = [x.to(self.device, non_blocking=True) if torch.is_tensor(x) else x for x in self.next_inputs]
            else:
                self.next_inputs = self.next_inputs.to(self.device, non_blocking=True)

    def next(self):
        torch.cuda.current_stream(self.device).wait_stream(self.stream)
        inputs = self.next_inputs
        self.preload()
        return inputs
```

* 辅助优化
    * 使用persistent_workers=True，避免每个 epoch 都重新启动数据加载进程。
    * 合理调参num_workers（一般为 CPU核心数//2 或 batch_size//2），避免过大会导致内存占用过高，过小会导致数据加载速度过慢。
    * 开启pin_memory=True，将数据.pin_memory()到pinned memory中，避免CPU数据转换为GPU数据时的memcpy操作。