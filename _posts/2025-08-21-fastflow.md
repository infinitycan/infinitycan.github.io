---
layout: post
title: "FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows"
subtitle: ""
date: 2025-08-21
author: "Can"
header-img: "img/boy.jpg"
mathjax: true
tags: ["Paper Reading", "Anomaly Detection", "Unsupervised-Learning", "arXiv"]
---

论文链接：[Paper](https://arxiv.org/pdf/2111.07677)

代码链接：[Code](https://github.com/gathierry/FastFlow)

**论文来源：arXiv 2021**

## Background
* 在数据中异常概率密度低，正态和异常数据通常呈现严重的长尾分布，甚至在某些情况下没有异常样本。现实状况使得在实践中很难收集和标注大量的异常数据用于监督学习。
* 无监督异常检测和定位能够用于在无法收集和标记足够的异常数据的情况进行。

## Motivation
现有的无监督异常检测方法主要基于深度学习，通过提取正常图像的特征并建模其分布，然后通过测量测试图像特征与估计分布之间的距离来计算异常分数。然而，这些方法在将图像特征映射到可处理的基础分布时效果不佳，并且忽略了局部和全局特征之间的关系，这对于识别异常至关重要。因此，文章提出了一种新的方法来解决这些问题。

**提出基于2D Normalizing Flows 的FastFlow**
* 使用全卷积网络和二维损失函数有效建模全局和局部分布。
* 采用大和小卷积核的交替堆叠，支持端到端推理，并具有高效率。
* 可以作为各种不同特征提取器的插件模型（plug-in module）使用。
![example](\img\in-post\image-dqlo.png)

## Method
### Problem Definition and Basic Methodology
#### Problem Definition
异常检测的目标是训练模型以达到区分测试数据是否为异常，而异常定位的目标是需要更细粒度的结果，为每个像素提供异常标签。
#### Basic Methodology
* 使用基于表示方法的可学习的概率密度估计模型，包含特征提取器和二维流动模型。
* 在训练阶段仅使用正常数据，在测试阶段正常数据和异常数据同时出现。
* 主流方法为从正态图像或正态图像patchs中提取判别特征向量，构造分布，并根据测试图像embedding与distribution之间的距离计算异常分数（anomaly score），具体步骤为：
    * 在测试数据集中使用CNN等提取特征，记为D = {x1, x2, · · · , xN }，其中xi由pX (x)采样得来。
    * 定义P = {Pθ : θ ∈ Θ}为异常检测模型，θ为可学习参数，将原始分布pX (x)中的所有xi映射到相同的分布pZ(z)。
    * 在分布中映射出异常像素或实例，供模型进行异常检测工作。
* **本文的方法也采取上述这种representation-based处理策略。**

### Framework
![Framework](\img\in-post\image-dqmz.png)

### Feature Extractor
* 异常检测任务中的一个重大挑战是如何把握全局关系，将异常区域与其他局部区域区分开来。
* 本文使用ResNet/Vision Transformer作为图像特征提取工具，将原始图像提取为features。
    * 由于ViT具有更强的捕捉局部patch和全局feature之间关系的能力，在使用ViT作为特征提取器时，只使用某一层的feature。
    * 对于ResNet而言本文直接在前三个块中使用最后一层的特征。
* 将得到的features放入三个相应的FastFlow模型。

### 2D Flow Model
**使用bijective invertible mapping（双射可逆映射）将图像特征x ∈ pX (x) 映射（f）到z ∈ pZ(z)**
#### bijection function
<img src="\img\in-post\image-zvmi.png" alt="bijection function" style="zoom:90%;" />
公式（1）描述了在归一化流中，如何通过变量变换来计算新变量的概率密度函数。这个公式的关键在于，它允许我们将一个已知的简单分布pZ(z) 转换为一个更复杂的分布pX(x)，同时通过雅可比行列式来调整概率密度，以保证变换的双射性质。
可以使用公式（2）从pZ (z)估计图像特征的对数似然，这个公式是对数似然估计，它计算了输入特征x的对数概率密度。
<img src="\img\in-post\image-wecl.png" alt="log likelihood" style="zoom:90%;" />
其中参数分别是：
<img src="\img\in-post\image-npjf.png" alt="parameters" style="zoom:90%;" />
在实际应用中，我们通常无法直接计算pX(x)，但通过归一化流，我们可以容易地计算pZ(z) 和雅可比行列式，从而间接估计pX(x)。这对于生成模型和概率推断非常重要，因为它们允许我们评估新样本属于训练数据分布的概率。

在推理中，异常图像的特征应该分布外泛化（out of distribution）的，因此具有比正常图像更低的似然，似然可以作为异常评分。**本文对图像每个通道的二维概率求和得到最终的概率图，并使用双线性插值将其上采样到输入图像分辨率以展示最终的异常区域。**
流模型f是由多个可逆变换块$f_i$按以下顺序堆叠而成：
<img src="\img\in-post\image-jjyu.png" alt="flow model" style="zoom:90%;" />
每一个$f_i$转换块都包含了多个步骤（steps），在每个区块中使用仿射耦合层，每个步骤的公式如下:
<img src="\img\in-post\image-gtlp.png" alt="flow step" style="zoom:90%;" />

1. 分割操作（第一行）：输入特征y被分割成两个部分，ya和yb。这个分割操作通常是沿着通道维度进行的，意味着输入特征图被分成两个子集。
2. 变换操作（第二行）：
    1. ya′ 是 ya 的直接复制，没有经过任何变换
    2. yb′ 是通过对 ya 进行一个可学习的变换 s(ya)，然后与 yb 进行逐元素乘法（⊙ 表示逐元素乘法，即Hadamard乘积），再加上另一个以 ya 为输入的可学习变换 b(ya) 来生成的。这里，s 和 b 是两个神经网络子网络，它们可以是全连接层或者其他类型的层。
3. 连接操作（第三行）：变换后的特征ya′ 和yb′ 被重新连接形成新的特征y′。这个连接操作也是沿着通道维度进行的。

本文使用了全卷积网络来保持空间信息，并且交替使用 3x3 和 1x1 的卷积层，这样做的目的是为了在变换过程中保留输入特征的空间结构信息。这个流步骤的目的是通过对输入特征的局部区域进行可逆的、参数化的变换来建模数据的分布。由于这个过程是可逆的，我们可以从潜在变量z重构输入特征x，并且由于变换的双射性质，我们可以计算出变换的雅可比行列式，通过多个这样的流步骤堆叠起来，可以构建一个复杂的模型来逼近复杂的数据分布。每一步都保持了数据的双射映射，从而使得从潜在空间到数据空间的映射是可逆的，并且可以计算概率密度。

### Steps
1. 对数概率密度:归一化流模型会输出每个数据点的对数概率密度（或称为得分）。这个值表示数据点属于模型训练时所学习到的“正常”数据分布的可能性。
2. 阈值设定:设定一个阈值来区分正常数据和异常数据。这个阈值可以基于多种方法确定：
    * 经验值：基于先前的知识或实验确定一个固定的阈值。
    * 数据驱动：通过分析正常数据的对数概率密度分布来动态确定阈值，例如，选择一个值使得特定百分比的数据被标记为正常。
    * 验证集：在一个独立的验证集上测试不同的阈值，选择在异常检测任务上表现最好的阈值。
3. 异常判定：根据阈值与对数概率密度的大小关系进行判定。
4. 概率映射：对数概率密度本身可以被看作是一个异常得分图，其中概率密度越低的区域表示异常的可能性越大。
5. 定位异常：生成一个异常得分图，该图与输入图像具有相同的空间分辨率。在这个得分图中，高异常得分的区域可以被突出显示，以定位异常的具体位置。
6. 结果分析：根据异常得分图和设定的阈值来解释结果，确定哪些区域是异常的。

## Experiment
### Datasets
* MVTec AD、BTAD:具有像素级注释的工业缺陷检测数据集，用于异常检测与异常定位。
* CIFAR-10：图像分类数据集，用于异常检测。

### Metrics
* AUROC（image or pixel level）
* Single Anomaly Score（Detection Task）
* Pixel Anomaly Score（Localization Task）

### Results
![results](\img\in-post\image-rwko.png)
当使用Vision Transformer(Deit和Cait)作为特征提取器时，FastFlow可以达到99.4的图像级AUC，优于CFlow和Patch Core。在使用ResNet时也得达到比较好的效果。
![results-1](\img\in-post\image-zqbo.png)
![results-2](\img\in-post\image-osgi.png)
在MVTecAD数据集上观察到FastFlow在图像级达到99.4的AUC，在像素级达到98.5的AUC，在异常检测任务中优于其他方法。
![results-3](\img\in-post\image-rokb.png)
我们可以观察到FastFlow达到了97.0像素级的AUC，并且超过其他方法7%的AUC。
![results-4](\img\in-post\image-fshx.png)
**在实验中其中一类作为异常数据，其他类别作为正常数据。**
实验证明FastFlow方法优于这些比较方法。在三个不同的数据集上的结果表明，FastFlow方法可以适应不同的异常检测设置。

### Ablation Study
消融实验比较了不同骨干网子网在交替使用3 × 3和1 × 1卷积核和只使用3 × 3卷积核的AUC和推理速度情况。
![ablation-study](\img\in-post\image-xkmt.png)
从结果来看，对于具有较大模型容量的骨干网络（如CaiT和Wide-ResNet50-2），交替使用3×3和1×1卷积层可以在减少参数数量的同时获得更高的性能。而对于模型容量较小的骨干网络（如DeiT和ResNet18），仅使用3×3卷积层表现更好。

### Process Visualization
![process-visualization](\img\in-post\image-bvzy.png)
FastFlow成功地将原始分布转化为标准正态分布。然后，将噪声干扰加入到概率图中黄色箭头所示的特定空间区域，并使用逆Fastflow模型从污染概率图中生成皮革特征张量，可以观察到在相应的污染位置出现了新的异常。

## Conclusion
* 本文中提出了一种名为FastFlow的新方法用于无监督异常检测和定位。该模型具有轻量级结构，能够综合考虑全局和局部信息，采用可学习的分布建模方法，以及高效的推理过程，将正态图像的特征分布在训练中投影到标准正态分布，并在测试中使用概率作为异常分数。
* FastFlow可以在ResNet、ViT等典型的特征提取网络中以插件的形式使用。在MVTec AD数据集上测试时性能优异。