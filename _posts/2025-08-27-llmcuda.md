---
layout: post
title: "LLM微调时遇到的CUDA版本问题"
subtitle: "CUDA概念体系区分"
date: 2025-08-27
author: "Can"
header-img: "img/cuda.jpeg"
tags: ["LLM", "CUDA"]
---

## Problem Description
最近在复现一个使用MOE + LORA 微调的[项目](https://github.com/liuqidong07/MOELoRA-peft)，在微调时遇到了CUDA版本问题，导致微调失败。
LLM微调需要用到各式各样的库，而这些库的版本之间存在着依赖关系，尤其是BitsAndBytes和LoRA这些高效微调技术都依赖于底层的 CUDA 优化。
* BitsAndBytes：该库需要与特定的 CUDA 版本和 PyTorch 版本精确匹配，才能实现 4-bit 量化等高效操作。
* DeepSpeed、Apex：包含了用 CUDA 编写的自定义内核（Custom Kernels），这些内核需要根据 GPU 架构和 CUDA 版本进行编译。
而我的CUDA软件驱动版本为12.6，通过`nvcc --version`命令可以查看CUDA版本为10.1.243
![cuda-driver-version](\img\in-post\image-driver.png)
![cuda-nvcc-version](\img\in-post\image-nvcc.png)

**CUDA 驱动版本和 CUDA 版本是不同的概念。CUDA 驱动版本是指安装在操作系统中的 CUDA 驱动程序的版本，而 CUDA 版本是指 CUDA 工具包的版本。通常情况下CUDA 版本小于或等于CUDA 驱动版本就是没什么问题的。**

但是这边有一个需要注意的问题：CUDA版本太旧的话，很多库是不支持的，比如我在安装BitsAndBytes的时候就报错了。
![cuda-bitsandbytes-error](\img\in-post\image-cuda-bits.png)

这个报错表明 bitsandbytes 库在检测 CUDA 环境时失败了，原因是它找不到与当前环境匹配的预编译库文件 libbitsandbytes_cuda126.so。尽管它检测到了 CUDA 运行时库 /usr/local/cuda-12.6/lib64/libcudart.so，但缺乏特定版本的.so文件导致它退而求其次，使用了性能低下的CPU版本。我们之前使用`nvcc -V`得到的CUDA工具包版本是10.1.243，那也就是说在安装bitsandbytes的时候，它会去查找CUDA10.1的库文件，但是我们的bitsandbytes似乎不支持这个旧版本，所以会报错。

遇到所有 bitsandbytes 问题的根源：

PyTorch 环境 是用 CUDA 10.2 编译的。

系统有一个 CUDA 12.6 的驱动。

bitsandbytes 在安装时，检测到了系统中的新版本 CUDA 12.6，并尝试为其编译或加载 libbitsandbytes_cuda126.so。

结果：需要的库文件 (libbitsandbytes_cuda126.so) 因为编译失败或版本不匹配而无法生成。同时，我的 PyTorch 又只兼容 CUDA 10.2，所以即使手动编译成功 libbitsandbytes_cuda126.so，它也无法与 PyTorch 正常工作。

## Solution
**解决办法就是升级CUDA版本到12.6**

所幸在我的服务器上的/usr/local路径下存在cuda-12.6的工具包，我们只需要在~/.bashrc文件中添加如下内容：
```bash
export PATH=/usr/local/cuda-12.6/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64:$LD_LIBRARY_PATH
```
然后执行`source ~/.bashrc`即可。
这时再执行`nvcc -V`命令，就可以看到CUDA版本已经升级到12.6了。
![cuda-126-version](\img\in-post\image-nvcc-12.png)
重新使用`pip install bitsandbytes`命令安装bitsandbytes就可以成功了。
除此之外还需要使用cuda12.1或者低于12.6（CUDA软件驱动版本）的PyTorch版本。

**在CUDA软件驱动版本为12.6，CUDA工具包版本为12.6，PyTorch的版本为2.5.1+cu121的情况下，模型能够正常训练和推理。**

## CUDA 
### CUDA 驱动 (CUDA Driver)：
CUDA 驱动是安装在操作系统上的底层软件，它是 NVIDIA 显卡运行的基础。这个驱动负责：
* 让操作系统识别GPU；
* 提供一个核心接口，允许应用程序（如 PyTorch）与 GPU 通信；
* **CUDA 驱动的版本决定了能运行的最高 CUDA 版本。** 例如，一个 12.6 版本的驱动可以运行任何 CUDA 12.x 或更低版本的程序。但旧驱动通常无法支持新版本的 CUDA。

### CUDA 工具包 (CUDA Toolkit)：
CUDA 工具包是 NVIDIA 提供的开发环境，包含了用于编写 CUDA 程序的工具和库。它包括：
* **nvcc 编译器**：用于将 CUDA 代码（.cu 文件）编译成 GPU 能够执行的二进制文件。
* **CUDA 库**：提供了 GPU 上的数学函数、并行算法和其他实用工具。
* **运行时库（如 libcudart.so）：**这些库在程序运行时被调用，负责管理 GPU 内存、启动内核等。
* **CUDA_VERSION：**当你安装 CUDA 工具包时，它会带一个特定的版本号（如 11.8 或 12.1），这个版本号就是你 nvcc 编译器的版本。
**CUDA 工具包的版本与 CUDA 驱动的版本相关。**：驱动和工具包是分开的。可以在新版本的驱动上安装旧版本的工具包，反之则不行。因此，确保工具包版本小于或等于驱动版本。

### 高级库 (cuDNN, cuBLAS 等)：
这些是建立在 CUDA 基础之上的、针对特定计算任务优化的库。它们是可选的，但对于深度学习来说必不可少。
* cuDNN (CUDA Deep Neural Network Library)：专门用于加速深度学习的库。它提供了高度优化的卷积、池化、归一化等操作。几乎所有的深度学习框架（PyTorch、TensorFlow）都依赖它来加速训练和推理。
* cuBLAS (CUDA Basic Linear Algebra Subroutines)：用于加速线性代数运算，如矩阵乘法。这些运算在深度学习中无处不在，尤其是在全连接层中。

一句话总结：
* **CUDA 驱动版本决定了能运行的最高 CUDA 版本。**
* **CUDA 工具包版本与 CUDA 驱动版本相关，驱动和工具包是分开的。**
* **高级库（如 cuDNN, cuBLAS 等）是建立在 CUDA 基础之上的、针对特定计算任务优化的库。**
